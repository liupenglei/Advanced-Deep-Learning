# Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition

tag: SPP-Net, Objection Detection, R-CNN

## 简介

SPP-Net  的初衷是解决令人头疼的输入图像的尺寸固定的要求，无论是裁剪，拉伸或者是加边都会对模型的效果带来负面影响。那是什么原因导致的需要固定输入图像的尺寸呢？一个CNN网络结构通常由卷积层和全连接层组成，卷积层通过滑动窗口的形式得到下一层，卷积对输入图像的尺寸并没有要求，只是不同尺寸的输入会产生不同尺寸特特征层。但是全连接要求的输入向量的尺寸是固定的，这也进而导致了图像特征层尺寸的固定，从而影响可对输入图像的尺寸要求。SPP是介于特征层（卷积层的最后一层）和全连接之间的一种pooling结构，不同尺寸特特征图通过金字塔式多个层次的pooling，可以得到固定尺寸的输入，从而满足全连接的要求。SPP的思想无论是对于图像分类还是物体检测，都是适用的。

从生物学的角度讲，SPP也是更符合人类的视觉特征的，因为当我们看一个物体时，是不考虑物体的尺寸的，而是再更深的视觉系统中进行处理。

下面我们回到物体检测，在SPP-Net之前，物体检测效果最好的是R-CNN  。但R-CNN非常耗时，因为其再使用Selective Search提取候选区域后，对每张图的几千个候选区域重复的进行卷机操作。SPP-Net只需要在整张图片上运行一次卷积网络层，然后使用SPP-Net的金字塔的pooling思想在特征图上提取特征，这一操作将运行速度提升了上百倍。

作者的这一工作在ILSVRC2014上也取得了非常优秀的成绩（检测第二名，分类第三名）。

## 算法详解

### 分类

作者通过可视化卷机网络的Conv5层，发现卷积操作其实保存了输入图像的空间特征，且不同的卷积核可能响应不同的图像语义特征。如论文中提供的图1，通过第一张图片的特征图，我们可以看到filter-175倾向于响应多边形特征，filter-55倾向于响应圆形特征，通过第二张图可以看出，filter-66倾向于响应∧形状，而118则倾向于响应∨形状。上面这些响应是与输入图像的尺寸没有关系的，而是取决于图像的内容。

![](../.gitbook/assets/SPP-NET_1.png)

在传统的计算机视觉系列的方法中，我们首先可以通过SIFT或者HOG等方法提取图像特征，然后通过词袋或者空间金字塔的方法聚集这些特征 。同样我们也可以用类似的方法聚集卷机网络得到的特征，这便是SPP-Net的算法思想。

首先通过卷积网络提取输入图像（尺寸无要求）的特征，然后通过空间金字塔池化（SPP）的方法将不同的特征图聚集成相同尺寸的特征向量，这些长度相同的特征向量便可以用于训练全连接或者SVM。与传统的词袋方法对比，SPP保存了图像的空间特征。得到尺寸相同的特征向量后。

图2阐明了SPP的网络结构

![](../.gitbook/assets/SPP-NET_2.png)

图2中conv5层有256个卷积核，论文中使用了4\*4, 2\*2, 1\*1三个尺度的金字塔，在每个尺度的grid（大小和输入图像的尺寸有关）使用的是max pooling得到特征向量。将所有尺度的特征向量连在一起就得到了一个5376的特征的特征向量，该特征向量便是全连接的输入。通过分析可以看出，尽管输入到网络的图像的尺寸不一样，经过SPP-NET后，都会得到相同长度的特征向量。

该方法可以通过标准的BP进行调参，然而实际训练过程中，GPU更倾向于尺寸固定的输入图像（例如Mini-batch训练），为了能够使用现有的框架（Caffe）并同时考虑多尺度的因素，作者使用了多个不同固定输入图像尺寸的网络，这些网络是共享参数的。对于任意不同输入尺寸的卷积网络，经过卷积层得到conv5的尺度是a\*a，如果我们要使用金字塔的某层取一个n\*n的特征向量，则pooling层的窗口大小是$$\lceil a/n \rceil$$, 步长是$$\lfloor a/n \rfloor$$。可见，参数的是和输入图像的尺寸没有关系的，因此不同的网络之间权值是可以共享的。

在实验中，作者使用了224\*224和180\*180两个网络，将图像resize固定到其中一个尺寸后训练该网络，并将学到的参数共享到另外一个网络中。更具体的，作者每个epoch更换一种图像尺寸，训练结束后共享权值。

**注：作者根本没有实现训练不同大小输入的CNN的BP算法,只是针对各种各样大小不同的输入,定义出不同的网络,但这些网络实际上参数都相同,于是就可以用现有工具来训练.**

在测试时，由于不存在mini-batch，所以输入图像的尺寸是任意的。

## 检测

简单的回顾一下R-CNN。首先R-CNN利用Selective Search在输入图像上提取2000个左右的候选区域，将每个候选区域拉伸到227\*227的尺寸。使用标准的卷机网络训练这些候选区域，提取conv5特征层的特征用于训练n个2分类的SVM作为分类模型，一个回归器用于位置精校。R-CNN的性能瓶颈之一是在同一张图像上的2000个左右的候选区域上重复的进行卷积操作，这在测试过程是非常耗时的。

SPP-NET首先在输入图像上提取2000个候选区域。按照图像的短边（缩小到s）将图片resize后，使用卷积网络提取**整张图片**的特征（提升时间的最关键部分）。找到每个候选区域对应的conv5特征图的部分，使用金字塔池化的方法提取长度固定的特征向量。特征向量后经过一个全连接后输入到二分类SVM中用于训练SVM分类器。同R-CNN一样，SPP-NET也使用了n个二分类的SVM。过程如图3.

![](../.gitbook/assets/SPP-NET_3.png)

在上面一段中，我们提要了要找到原图的候选区域在特征层对应的相对位置。由于卷积操作并不影响物体在图像中的相对位置，这就涉及到感受野（Receptive Field）的计算问题。感知野是从第一层全连接从后往前推，公式是

$$
rfsize = (out-1) \times stride + ksize
$$

其中out是上一层感知野的大小，stride是步长，ksize和核函数的大小。

根据论文中给出的ZF-5Net的网络结构，便得出了论文附录A中感知野139的计算方法：

![](../.gitbook/assets/SPP-NET_4.png)

1. conv5: $$fsize = (1 - 1) \times 1 + 3 = 3$$
2. conv4: $$fsize = (3 - 1) \times 1 + 3 = 5$$
3. conv3: $$fsize = (5 - 1) \times 1 + 3 = 7$$
4. conv2\(LRN\): $$fsize = (7 - 1) \times 2 + 3 = 15$$
5. conv2: $$fsize = (15 - 1) \times 2 + 5 = 33$$
6. conv1\(LRN\): $$fsize = (33 - 1) \times 2 + 5 = 67$$
7. conv1: $$fsize = (67 - 1) \times 2 + 7 = 139$$

每经过一次stride=2的操作，相当于进行一次降采样，共四次stride，也就是特征层的一个像素相当于原图的16的步长。根据论文 , 可以得到类似的结果，后面有时间的话，会给出这篇论文的总结。

同时，作者指出，SPP-NET的卷积网络是可以使用候选区域进行微调的。针对候选区域的类别特征（N+1）作者在全连接的最后一层又接了一个n+1类的全连接，在实验中，作者通过conv5层提取的特征层没有经过微调，只是微调了一下全连接层。使用的数据是25%的正样本（和ground truth的重合度大于50%）。

和R-CNN一样，作者也使用了回归器用于位置矫正，特征同样是从conv5层提取的特征。

